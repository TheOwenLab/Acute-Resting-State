{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/env python\n", "# coding: utf-8"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Predict outcome variable Var using 10 Resting State Networks fed to the Nearest Centroid Algorithm "]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Data Loading and Organization"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[151]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load in required libaries "]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[152]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "import pandas as pd\n", "import os \n", "import numpy as np\n", "from sklearn.model_selection import train_test_split, StratifiedKFold\n", "from sklearn.metrics import confusion_matrix, roc_auc_score,plot_confusion_matrix, balanced_accuracy_score\n", "from sklearn.neighbors import NearestCentroid\n", "from sklearn.preprocessing import MinMaxScaler\n", "from scipy.stats import sem, iqr, norm"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[153]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["change current directory to where you have stored the data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[154]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["set current working directory"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["path_to_data = os.getcwd()\n", "os.chdir(path_to_data)    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[155]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["network names"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[156]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["networkLabs = [\"medial visual\", \"occipital pole visual\", \"lateral visual\", \"default mode\", \"cerebellar\", \"sensorimotor\", \"auditory\",  \"executive control\", \"right frontoparietal\", \"left frontoparietal\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[157]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["get index for networks used in prediction    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[158]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["RSNidx = np.linspace(0,len(networkLabs) -1,len(networkLabs)).astype('int')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[159]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["load in datafile with resting state spatial correlations"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dfML = pd.read_csv(\"SpatialCorrelation.csv\")\n", "# load in outcome file\n", "dfOutcome = pd.read_csv(\"ClinicalInformation.csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[160]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["drop patients with unacceptably large motion artifacts from the dataset"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[161]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bSubs = [8,18]; \n", "dfML = dfML[(dfML[\"Subjects\"] != bSubs[0]) & (dfML[\"Subjects\"] != bSubs[1])]\n", "dfOutcome = dfOutcome[(dfOutcome[\"Patient\"] != bSubs[0]) & (dfOutcome[\"Patient\"] != bSubs[1])].reset_index()\n", "# resort subject index \n", "dfML['Subjects'] = np.arange(0,25)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[162]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["optionally drop networks from analysis"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[163]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["keepNets = [\"Subjects\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"]\n", "netIdx = [int(num)-1 for num in keepNets[1:]]\n", "networkLabs = np.array(networkLabs)[netIdx]\n", "print(networkLabs)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[164]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["make a numpy array from the networks kept in the analysis"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = np.array(dfML.loc[:,keepNets])\n", "X = X[:,1:]\n", "# apply fisher transform to new patients (who were concatenated from a new dataset)\n", "X[18:,:] = np.arctanh(X[18:,:])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[165]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["scale features to minmax"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scaler = MinMaxScaler()\n", "# apply min max scaler\n", "X = scaler.fit_transform(X)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[166]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["sort behavioural data  "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dfOutcome[\"AgeNew\"] = dfOutcome[\"Age\"]\n", "dfOutcome['RCNew']  = dfOutcome['GOS'] > 2\n", "dfOutcome['GOSNew'] = dfOutcome[\"GOS\"] > 3\n", "dfOutcome[\"FinalGOSNew\"] = dfOutcome[\"Final GOS\"] > 3\n", "dfOutcome['SexNew'] = dfOutcome[\"Sex\"] == \"M\"\n", "dfOutcome[\"TOSNew\"] = np.log10(dfOutcome['Time of Scan post-ictus'])\n", "dfOutcome[\"GCSNew\"] = dfOutcome[\"GCS Total\"].fillna(value = np.mean(dfOutcome[\"GCS Total\"])).values \n", "dfOutcome[\"GCSENew\"] = dfOutcome[\"GCS_E\"].fillna(value = np.mean(dfOutcome[\"GCS_E\"])).values \n", "dfOutcome[\"GCSMNew\"] = dfOutcome[\"GCS_M\"].fillna(value = np.mean(dfOutcome[\"GCS_M\"])).values \n", "#dfOutcome[\"SedationNew\"] = dfOutcome[\"Sedation\"].astype(\"int\")\n", "#dfOutcome[\"SedationNew\"] = dfOutcome[\"SedationNew\"].astype(\"boolean\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Initalize paramaters and storage for the Nearest Centroid Model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[167]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nIter = 1000\n", "test_size = 0.30\n", "np.random.seed(59)\n", "Var = \"GOSNew\" # which variable do we want to predict based on resting state connectivity \n", "Yout = np.array(dfOutcome[Var]) # outcome variable\n", "Xact = X; \n", "Xo = scaler.inverse_transform(X) # use original spatial correlation values for plotting"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[168]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["initalize machine learning parameters and results df"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Pred = [];\n", "nSub = Xact.shape[0]; ts = int(test_size * nSub) # test size\n", "# results dataframe\n", "pR = pd.DataFrame()\n", "pR['Subject'] = list(range(0,nSub)) # patient index\n", "pR['Results'] = np.zeros(nSub) # whether 0 or 1\n", "pR['nIter'] = np.zeros(nSub) # number of iterations patient was involved in testing"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[169]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["create null columns in df to store chance level predictions and features"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pR['ResultsNull'] = np.zeros(nSub)   \n", "PredNull = [];"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[170]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["fix the leave participant out index for reproducibility"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["randIdx = np.zeros((nIter,nSub)) * np.nan;\n", "subList = np.array(range(0,nSub))\n", "for nn in range(0,nIter):\n", "    randIdx[nn,:] = np.random.permutation(subList)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nFold = 3; ResultsNull = np.ones((nIter,nSub)) * np.nan\n", "# #### Train the null model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[171]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tROCNull = np.zeros((nIter,nFold)); CentroidsNull = np.zeros((nIter,nFold,2,10))\n", "for kk in range(0,nIter):\n", "    # initalize random seed\n", "    # set train test indicies\n", "    #ridx = randIdx[kk].astype(\"int\")\n", "    # permute test array\n", "    yR = np.random.permutation(Yout) # only difference between null model and regular model \n", "    # gather train and test sets based on ridx\n", "    # run through a couple folds \n", "    kf = StratifiedKFold(n_splits = nFold, random_state=(59+kk), shuffle = True)\n", "    kcount = 0\n", "    for train_index, test_index in kf.split(Xact, yR):\n", "         X_train, X_test = Xact[train_index], Xact[test_index]\n", "         y_train, y_test = yR[train_index], yR[test_index]\n", "         # scambled y_test\n", "         y_test = np.random.permutation(y_test)\n", "         clf = NearestCentroid(metric = \"euclidean\")\n", "         clf.fit(X_train,y_train)\n", "         # store group predictions\n", "         predictionsn = clf.predict(X_test)\n", "         PredNull.append(predictionsn)\n", "         # store individual predictions\n", "         ResultsNull[kk,test_index] = predictionsn\n", "         # store feature weights\n", "         CentroidsNull[kk,kcount,:,:] = clf.centroids_ \n", "         tROCNull[kk,kcount] = balanced_accuracy_score(y_test,predictionsn)\n", "         kcount += 1\n", "             \n", "# In[172]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["compute label confidence and error of the null distribution"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pR['ResultsNull'] = np.mean(ResultsNull,axis = 0)\n", "dfOutcome['LabelConfNull'] = pR['ResultsNull']\n", "# point the confidence in the direction of the actual label\n", "### NOTE large confidence values means incorrect with high confidence\n", "### low confidence mean correct with high confidence\n", "dfOutcome[\"LabelConfNull\"] = (dfOutcome[\"LabelConfNull\"] - dfOutcome[Var]).abs()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[173]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["find the parameters of the null distribution"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nMeanS = dfOutcome.groupby(Var).mean()[\"LabelConfNull\"] # mean between the groups\n", "nErrorS = dfOutcome.groupby(Var).std()[\"LabelConfNull\"] # standard deviation between the groups\n", "nS = dfOutcome.groupby(Var).count()[\"LabelConfNull\"] # number of patients in each group\n", "nErrorSE = nErrorS * 1.96 # CI \n", "nMean = dfOutcome[\"LabelConfNull\"].mean(); nError = dfOutcome[\"LabelConfNull\"].std() # mean and std of null\n", "nCI = nError * 1.96 # CI of null"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Plot the Null Results"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[174]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.datasets import make_blobs\n", "import colorcet as cc"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[175]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.set_theme(style = \"white\", rc={'figure.figsize': (3.1,3.1),\"xtick.labelsize\": 12,             'xtick.alignment':'center',\"ytick.labelsize\": 12,'font.family':'Arial','legend.fontsize':12,'figure.dpi':600,             \"axes.labelsize\":12,\"figure.facecolor\":\"w\",\"axes.spines.right\": False,\"axes.spines.left\": False,                \"axes.spines.top\": False,\"axes.spines.bottom\": False})\n", "    \n", "blobs, labels = make_blobs(n_samples=1000, centers=25, center_box=(-100, 100))\n", "palette = sns.color_palette(cc.glasbey, n_colors=nSub)\n", "pal = sns.color_palette(\"hls\",16)    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[176]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots(1,1)\n", "sns.swarmplot(data = dfOutcome, x = Var, y = 'LabelConfNull',              palette = [pal[0],pal[-5]] ,s=7,ax = ax)\n", "x1 = ax.get_xbound()[0]; x2 = ax.get_xbound()[1]\n", "# draw indeterminant region if null is combined based on both outcomes\n", "ax.axhline(y = nMean, xmin = ax.get_xbound()[0], xmax = ax.get_xbound()[1]) \n", "# plot the confidence interval of the null distribution\n", "ax.fill_between([ax.get_xbound()[0],ax.get_xbound()[1]],nMean - nCI, nMean + nCI, alpha = 0.2)\n", "ax.fill_between([ax.get_xbound()[0],ax.get_xbound()[1]],-0.05, nMean - nCI, alpha = 0.2, color=\"green\")\n", "ax.fill_between([ax.get_xbound()[0],ax.get_xbound()[1]],nMean + nCI,1.05, alpha = 0.2, color=\"red\")\n", "plt.xlabel(Var)\n", "plt.ylim([0,1])\n", "ax.set_xlabel(\"Outcome\")\n", "ax.set_ylim([-0.05,1.05])\n", "ax.set_yticks([0,0.25,0.5,0.75,1])\n", "ax.set_yticklabels([\"100%\",\"75%\",\"50%\",\"75%\",\"100%\"]) # change tick labels to make the results more interpretable\n", "ax.set_ylabel(\"Confidence\")\n", "ax.set_xticklabels([\"Poor\",\"Good\"])\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["plot null group results"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots(1,1)\n", "plt.hist(np.mean(tROCNull,axis = 1),color = pal[9])\n", "ax.set_ylabel(\"Frequency\"); ax.set_xlabel(\"Null Balanced Accuracy\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Train the actual model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[181]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Results = np.ones((nIter,nSub)) * np.nan"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[182]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tROC = np.zeros((nIter,nFold))\n", "CentroidsReal = np.zeros((nIter,nFold,2,10))\n", "for kk in range(0,nIter):\n", "    # gather train and test sets  \n", "    # run through a couple folds \n", "    kf = StratifiedKFold(n_splits = nFold, random_state=(59 + kk), shuffle = True)\n", "    kcount = 0\n", "    for train_index, test_index in kf.split(Xact, yR):\n", "         #print(train_index.shape); print(test_index.shape); print(kk)\n", "         X_train, X_test = Xact[train_index], Xact[test_index]\n", "         y_train, y_test = Yout[train_index], Yout[test_index]\n", "         clf = NearestCentroid(metric = \"euclidean\")\n", "         clf.fit(X_train,y_train)\n", "         # store group predictions\n", "         predictions = clf.predict(X_test)\n", "         Pred.append(predictions)\n", "         # store individual predictions\n", "         Results[kk,test_index] = predictions\n", "         # store feature weights\n", "         CentroidsReal[kk,kcount,:,:] = clf.centroids_\n", "         tROC[kk,kcount] = balanced_accuracy_score(y_test,predictions)    \n", "         kcount += 1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[183]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["store CI and descriptives of group results"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mtROC = np.mean(tROC); medtROC = np.median(tROC)\n", "stROC = sem(tROC); iqrtROC = iqr(tROC)\n", "prtROC = np.percentile(tROC,[25,75])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[184]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["tore actual label confidence"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dfOutcome['LabelConf'] = np.mean(Results,axis = 0)\n", "# point the confidence in the direction of the actual label\n", "### NOTE large confidence values means incorrect with high confidence\n", "### low confidence mean correct with high confidence\n", "dfOutcome[\"LabelConf\"] = (dfOutcome[\"LabelConf\"] - dfOutcome[Var]).abs() "]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[185]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig,ax = plt.subplots()\n", "sns.swarmplot(data = dfOutcome, x = Var, y = 'LabelConf', palette = [pal[0],pal[-5]],s=5,ax = ax)\n", "x1 = ax.get_xbound()[0]; x2 = ax.get_xbound()[1]\n", "ax.axhline(y = nMean, xmin = ax.get_xbound()[0], xmax = ax.get_xbound()[1]) \n", "# draw indeterminant region if null combined for both outcome groups\n", "ax.fill_between([ax.get_xbound()[0],ax.get_xbound()[1]],nMean - nCI, nMean + nCI, alpha = 0.2)\n", "ax.fill_between([ax.get_xbound()[0],ax.get_xbound()[1]],-0.05, nMean - nCI, alpha = 0.2, color=\"green\")\n", "ax.fill_between([ax.get_xbound()[0],ax.get_xbound()[1]],nMean + nCI,1.05, alpha = 0.2, color=\"red\")\n", "sns.despine(top=True, right=True, left=True, bottom=True)\n", "ax.set_xlabel(\"Outcome\")\n", "ax.set_ylim([-0.05,1.05])\n", "ax.set_yticks([0,0.25,0.5,0.75,1])\n", "ax.set_yticklabels([\"100%\",\"75%\",\"50%\",\"75%\",\"100%\"]) # make the ylabel more readable\n", "ax.set_ylabel(\"Confidence\")\n", "ax.set_xticklabels([\"Poor\",\"Good\"])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[186]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["plot without change in axis for context"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["g = sns.catplot(data = dfOutcome, x = Var, y = \"LabelConf\", palette = \"Paired\",s=10,kind = \"swarm\")\n", "plt.axhline(y = nMean, xmin = g.ax.get_xbound()[0], xmax = g.ax.get_xbound()[1]) \n", "#plot the confidence interval of the null distribution\n", "plt.fill_between([g.ax.get_xbound()[0],g.ax.get_xbound()[1]],nMean - nError, nMean + nError, alpha = 0.2)\n", "plt.fill_between([g.ax.get_xbound()[0],g.ax.get_xbound()[1]],-0.05, nMean - nError, alpha = 0.2, color=\"green\")\n", "plt.fill_between([g.ax.get_xbound()[0],g.ax.get_xbound()[1]],nMean + nError,1.05, alpha = 0.2, color=\"red\")\n", "plt.xlabel(Var)\n", "sns.despine(top=True, right=True, left=True, bottom=True)\n", "plt.ylabel(\"Label Error\")\n", "plt.xticks([0,1],[\"No\",\"Yes\"])\n", "plt.ylim([-0.05,1.05])\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": [""]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[187]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot when null is produced by the different outcome groups"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig,ax = plt.subplots(nrows = 1, ncols = 1)\n", "g = sns.swarmplot(data = dfOutcome, x = Var, y = \"LabelConf\",palette = [pal[0],pal[-5]],s=5,ax = ax)\n", "#g = sns.swarmplot(data = dfOutcome, x = Var, y = \"LabelConf\", hue = \"StudyID\",s=5,ax = ax)\n", "# plot the confidence interval of the null distribution\n", "x1 = ax.get_xbound()[0]; x2 = ax.get_xbound()[1]\n", "nS = dfOutcome.groupby(Var).count()[\"LabelConfNull\"]\n", "nErrorSE = nErrorS * 1.96\n", "# draw indeterminant region\n", "plt.fill_between([x1,(x2+x1)/2],nMeanS[False] - nErrorSE[False],                  nMeanS[False] + nErrorSE[False], alpha = 0.2,color = \"blue\")\n", "plt.fill_between([(x2+x1)/2,x2],nMeanS[True] - nErrorSE[True],                  nMeanS[True] + nErrorSE[True], alpha = 0.2,color = \"blue\")\n", "# draw False side\n", "plt.fill_between([x1,(x2+x1)/2],-0.05, nMeanS[False] - nErrorSE[False], alpha = 0.2, color=\"green\")\n", "plt.fill_between([x1,(x2+x1)/2],nMeanS[False] + nErrorSE[False],1.05, alpha = 0.2, color=\"red\")\n", "# draw True side\n", "plt.fill_between([(x2+x1)/2,x2],-0.05, nMeanS[True] - nErrorSE[True], alpha = 0.2, color=\"green\")\n", "plt.fill_between([(x2+x1)/2,x2],nMeanS[True] + nErrorSE[True],1.05, alpha = 0.2, color=\"red\")\n", "plt.axhline(y = nMeanS[False], xmin = x1 ,xmax = (x2+x1)/2)\n", "plt.axhline(y = nMeanS[True], xmin = (x2+x1)/2 ,xmax = x2)\n", "plt.xlabel(\"Outcome\")\n", "sns.despine(top=True, right=True, left=True, bottom=True)\n", "plt.ylabel(\"\")\n", "plt.xticks([0,1],[\"Poor\",\"Good\"])\n", "ax.set_yticks([0,0.25,0.5,0.75,1])\n", "ax.set_yticklabels([\"100%\",\"75%\",\"50%\",\"75%\",\"100%\"])\n", "ax.set_ylabel(\"Confidence\")\n", "plt.ylim([-0.05,1.05])\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Observe classification performance "]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[188]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["misclassifed people based on null based on combining the null distribution of outcomes"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dfOutcome[\"ResultTrue\"] = 1\n", "# those with positive outcome\n", "po = dfOutcome[dfOutcome[Var] == True][\"LabelConf\"]\n", "no = dfOutcome[dfOutcome[Var] == False][\"LabelConf\"]\n", "dfOutcome[\"ResultTrue\"].loc[dfOutcome[Var] == True] = po < (nMean - nCI)\n", "dfOutcome[\"ResultTrue\"].loc[dfOutcome[Var] == False] = no < (nMean - nCI)\n", "# what were the actual predictions?\n", "predtrue = np.ones((nSub,)) * np.nan\n", "vpPred = dfOutcome[\"LabelConf\"][dfOutcome[Var] == True] < (nMean - nCI)\n", "vnPred= dfOutcome[\"LabelConf\"][dfOutcome[Var] == False] > (nMean - nCI)\n", "predtrue[dfOutcome[Var][(dfOutcome[Var] == True)].index] = vpPred\n", "predtrue[dfOutcome[Var][(dfOutcome[Var] == False)].index] = vnPred"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[189]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["sort into true and false positives"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tp = np.sum(dfOutcome[dfOutcome[Var] == True]['ResultTrue'] == True);\n", "tn = np.sum(dfOutcome[dfOutcome[Var] == False]['ResultTrue'] == True);\n", "fp = np.sum(dfOutcome[dfOutcome[Var] == False]['ResultTrue'] == False)\n", "fn = np.sum(dfOutcome[dfOutcome[Var] == True]['ResultTrue'] == False)\n", "specificity = tn / (tn + fp)\n", "sensitivity = tp / (tp + fn)\n", "# print results\n", "print(\"Sensitivity: \", sensitivity)\n", "print(\"Specificity: \", specificity)\n", "print(\"Individual Balanced Accuracy:\", balanced_accuracy_score(dfOutcome[Var],predtrue))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[190]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["misclassifed people based on null separated between outcomes"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dfOutcome[\"Result\"] = 1\n", "# those with positive outcome\n", "po = dfOutcome[dfOutcome[Var] == True][\"LabelConf\"]\n", "no = dfOutcome[dfOutcome[Var] == False][\"LabelConf\"]\n", "dfOutcome[\"Result\"].loc[dfOutcome[Var] == True] = po < (nMeanS[True] - nErrorSE[True])\n", "dfOutcome[\"Result\"].loc[dfOutcome[Var] == False] = no < (nMeanS[False] - nErrorSE[False])\n", "# what were the actual predictions?\n", "pred = np.ones((nSub,)) * np.nan\n", "vpPred = dfOutcome[\"LabelConf\"][dfOutcome[Var] == True] < (nMeanS[True] - nErrorSE[True])\n", "vnPred= dfOutcome[\"LabelConf\"][dfOutcome[Var] == False] > (nMeanS[False] - nErrorSE[False])\n", "pred[dfOutcome[Var][(dfOutcome[Var] == True)].index] = vpPred\n", "pred[dfOutcome[Var][(dfOutcome[Var] == False)].index] = vnPred"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[191]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tp = np.sum(dfOutcome[dfOutcome[Var] == True]['Result'] == True);\n", "tn = np.sum(dfOutcome[dfOutcome[Var] == False]['Result'] == True);\n", "fp = np.sum(dfOutcome[dfOutcome[Var] == False]['Result'] == False)\n", "fn = np.sum(dfOutcome[dfOutcome[Var] == True]['Result'] == False)\n", "specificity = tn / (tn + fp)\n", "sensitivity = tp / (tp + fn)\n", "print(\"Sensitivity: \", sensitivity)\n", "print(\"Specificity: \", specificity)\n", "print(\"Individual Balanced Accuracy:\", balanced_accuracy_score(dfOutcome[Var],pred))"]}, {"cell_type": "markdown", "metadata": {}, "source": [" Generally the results of these two appraoches are consistent, but it is unclear which is more appropriate."]}, {"cell_type": "markdown", "metadata": {}, "source": [" statistically evaluate group level results<br>\n", "take average over each fold"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["GroupBalancedAccuracy = np.mean(tROC,1)\n", "GroupBalancedAccuracyMed = np.median(tROC,1)\n", "# take average of null\n", "GroupBalancedAccuracyNull = np.mean(tROCNull,1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["get parameters of the results"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Mu = np.mean(GroupBalancedAccuracy); Sigma = np.std(GroupBalancedAccuracy)\n", "print(\"Group Balanced Accuracy\",Mu)\n", "NullMu = np.mean(GroupBalancedAccuracyNull); NullSigma = np.std(GroupBalancedAccuracyNull)\n", "# get confidence interval\n", "GroupCI = Sigma * 1.96\n", "print(\"Group Balanced Accuracy Confidence Interval\", \"[\", Mu - GroupCI, \",\",Mu + GroupCI,\"]\")\n", "# get significance \n", "ZGroup = (Mu - NullMu)/NullSigma\n", "PGroup = norm.sf(ZGroup) \n", "print(\"Z Score Group\",ZGroup)\n", "print(\"p value Group\", PGroup)\n", "# #### Compute statistics on label confidence values "]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[193]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["or nulls separated between outcomes"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["zval = np.ones((nSub,)) * np.nan\n", "vt = dfOutcome[\"LabelConf\"][dfOutcome[Var] == True                                               ].apply(lambda x: ((x - nMeanS[True])/nErrorS[True]))\n", "vf = dfOutcome[\"LabelConf\"][dfOutcome[Var] == False                                               ].apply(lambda x: ((x - nMeanS[False])/nErrorS[False]))\n", "zval[dfOutcome[Var][(dfOutcome[Var] == True)].index] = vt\n", "zval[dfOutcome[Var][(dfOutcome[Var] == False)].index] = vf\n", "dfOutcome[\"z-value\"] = zval"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[194]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["or nulls based on combining outcome"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["zval = np.ones((nSub,)) * np.nan\n", "vt = dfOutcome[\"LabelConf\"][dfOutcome[Var] == True                                               ].apply(lambda x: ((x - nMean)/nError))\n", "vf = dfOutcome[\"LabelConf\"][dfOutcome[Var] == False                                               ].apply(lambda x: ((x - nMean)/nError))\n", "zval[dfOutcome[Var][(dfOutcome[Var] == True)].index] = vt\n", "zval[dfOutcome[Var][(dfOutcome[Var] == False)].index] = vf\n", "dfOutcome[\"z-value-true\"] = zval\n", "dfOutcome[\"p-value-true\"] = np.round(norm.sf(-dfOutcome[\"z-value-true\"]),6)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["print confidence scores for incorrect and correct people"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tConf = dfOutcome[dfOutcome[\"ResultTrue\"] == 1][\"LabelConf\"]\n", "tConf = 1 - tConf\n", "fConf = dfOutcome[dfOutcome[\"ResultTrue\"] == 0][\"LabelConf\"]\n", "print(\"Mean Confidence Correct \",np.mean(tConf))\n", "print(\"Mean Confidence Incorrect \",np.mean(fConf))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"STD Confidence Correct \",np.std(tConf))\n", "print(\"STD Confidence Incorrect \",np.std(fConf))\n", "# #### Plot confusion matrix"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[195]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from  matplotlib.colors import LinearSegmentedColormap\n", "cmap=LinearSegmentedColormap.from_list('Custom',[\"red\",\"white\", \"green\"], N=123) \n", "groupProb = confusion_matrix(dfOutcome[Var],predtrue)\n", "sns.set_theme(style = \"white\", rc={'figure.figsize': (3.1,3.1),\"xtick.labelsize\": 10,             'xtick.alignment':'center',\"ytick.labelsize\": 10,'font.family':'Arial','figure.dpi':500,             \"axes.labelsize\":12,\"figure.facecolor\":\"white\",'axes.facecolor':'white',\"axes.spines.right\": False,\"axes.spines.left\": False,                \"axes.spines.top\": False,\"axes.spines.bottom\": False})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[196]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.heatmap(groupProb, annot = True,cmap = cmap,annot_kws={\"fontsize\":12},cbar = False,vmin=4, vmax=8,alpha = 0.2)\n", "plt.xticks([0.5,1.5], labels = [\"Good Outcome\", \"Poor Outcome\"])\n", "plt.yticks([0.5,1.5], labels = [\"Good Outcome\", \"Poor Outcome\"])\n", "plt.xlabel(\"Actual Outcome\")\n", "plt.ylabel(\"Predicted Outcome\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Plot influential features<br><br>\n", "Plot influential centroids after controlling for chance level differences between centroid (based on CentroidNull).<br>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[197]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compute probability of centroid <br>\n", "determine distribution of centroids"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["CentroidsNull = np.mean(CentroidsNull,1) # average over folds\n", "nCentroids = np.stack(CentroidsNull)\n", "CentroidsReal = np.mean(CentroidsReal,1) # average over folds\n", "Centroids = np.mean(CentroidsReal,0)\n", "nullCentMean = np.mean(nCentroids[:,0,:] - nCentroids[:,1,:],axis = 0)\n", "nullCentStd = np.std(nCentroids[:,0,:] - nCentroids[:,1,:],axis = 0)\n", "# compute z score\n", "aCentroid = Centroids[0,:] - Centroids[1,:]\n", "zCentroid = (aCentroid - nullCentMean)/nullCentStd\n", "# compute p value of z-score\n", "from scipy.stats import norm\n", "norm.sf(abs(zCentroid))*2\n", "tnIdx = np.argsort(zCentroid)[0:3]\n", "fig = plt.figure()\n", "ax = plt.axes(projection =\"3d\")\n", "c = Yout\n", "x1 =  Xo[c,tnIdx[0]]; \n", "y1 = Xo[c,tnIdx[1]];\n", "z1 = Xo[c,tnIdx[2]];\n", "    # Create Plot\n", "ax.scatter3D(x1,y1,z1,c = pal[-5], s = 40)\n", "c = Yout == 0 \n", "x2 =  Xo[c,tnIdx[0]];\n", "y2 = Xo[c,tnIdx[1]];\n", "z2 = Xo[c,tnIdx[2]];\n", "    # Create Plot\n", "#ax.scatter3D(x2,y2,z2,c=\"blue\",s = dfOutcome[\"GCS_E\"][c].values * 100)\n", "ax.scatter3D(x2,y2,z2, c = pal[0],s = 40)\n", "ax.set_xlabel(\"\\n\" + networkLabs[tnIdx[0]])\n", "ax.set_ylabel(\"\\n\" + networkLabs[tnIdx[1]])\n", "ax.set_zlabel(\"\\n\" + networkLabs[tnIdx[2]])\n", "#ax.legend([\"Good Outcome\",\"Poor Outcome\"],bbox_to_anchor=(1.5, 1))\n", "#fig.suptitle(\"True Labels\")\n", "# Show plot\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["grab the networks with the largest difference between outcome but plot <br><br>\n", "as a function of correct vs. incorrectly labelled groups"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[198]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["grab the networks with the largest difference between outcome and plot<br>\n", "as a function of correct vs. incorrectly labelled groups"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Centroids = np.mean(CentroidsReal,0)\n", "# compute z score\n", "aCentroid = Centroids[0,:] - Centroids[1,:]\n", "zCentroid = (aCentroid - nullCentMean)/nullCentStd\n", "tnIdx = np.argsort(zCentroid)[0:3]\n", "# print significance\n", "print(\"Feature Importance\", -zCentroid)\n", "print(\"Feature Importance Significance\", norm.sf(np.abs(zCentroid))*2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[199]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize = (10, 7))\n", "ax = plt.axes(projection =\"3d\")\n", "# set cluster and values for label\n", "c = (dfOutcome[\"ResultTrue\"] == 0).values\n", "x1 =  Xo[c,tnIdx[0]]; \n", "y1 = Xo[c,tnIdx[1]];\n", "z1 = Xo[c,tnIdx[2]];\n", "    # Create Plot\n", "ax.scatter3D(x1,y1,z1,c=\"red\")\n", "c = (dfOutcome[\"ResultTrue\"] == 1).values\n", "x2 =  Xo[c,tnIdx[0]];\n", "y2 = Xo[c,tnIdx[1]];\n", "z2 = Xo[c,tnIdx[2]];\n", "    # Create Plot\n", "#ax.scatter3D(x2,y2,z2,c=\"blue\",s = dfOutcome[\"GCS_E\"][c].values * 100)\n", "ax.scatter3D(x2,y2,z2,c=\"blue\")\n", "ax.set_xlabel(\"\\n\" + networkLabs[tnIdx[0]])\n", "ax.set_ylabel(\"\\n\" + networkLabs[tnIdx[1]])\n", "ax.set_zlabel(\"\\n\" + networkLabs[tnIdx[2]], rotation=60)\n", "plt.legend([\"Incorrectly Labelled\",\"Correctly Labelled\"])\n", "#fig.suptitle(\"True Labels\")\n", "# Show plot\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### plot feature importance bar plots"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[200]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fNull = np.stack(CentroidsNull)\n", "# null of difference between group 1 and 2\n", "fNull = fNull[:,0,:] - fNull[:,1,:]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[201]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["create CI"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["CIh = np.mean(fNull) + (np.std(fNull) * 1.96)\n", "CIl = np.mean(fNull) - (np.std(fNull) * 1.96)\n", "centdf = pd.DataFrame([-aCentroid.T],columns = networkLabs)\n", "centnulldf = pd.DataFrame(fNull,columns = networkLabs)\n", "centnulldf = pd.melt(centnulldf,value_vars = networkLabs.tolist())\n", "centnulldf.columns = [\"Network\",\"Null\"]\n", "centnulldf[\"Network\"] = centnulldf[\"Network\"].astype(\"category\")\n", "fig,ax = plt.subplots(1,1)\n", "x = list(range(0,len(networkLabs)))\n", "sns.barplot(x,-aCentroid,palette = \"Paired\")\n", "ax.axhline(y = CIh, xmin = ax.get_xbound()[0], xmax = ax.get_xbound()[1],color = pal[-5]) \n", "ax.axhline(y = CIl, xmin = ax.get_xbound()[0], xmax = ax.get_xbound()[1],color = pal[0]) \n", "ax.set_ylim([-.4,.4])\n", "# plot the confidence interval of the null distribution\n", "ax.set_xticks(x)\n", "ax.set_xticklabels(networkLabs,rotation=90)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[202]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot as centroid difference"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig,ax = plt.subplots(1,1)\n", "x = list(range(0,len(networkLabs)))\n", "sns.barplot(x,-aCentroid,palette = \"Paired\",ax = ax)\n", "ax.set_xticks(x)\n", "ax.set_xticklabels(networkLabs,rotation=90)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[203]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["plot as z-score"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig,ax = plt.subplots(1,1)\n", "x = list(range(0,len(networkLabs)))\n", "sns.barplot(x,-zCentroid,palette = \"Paired\",ax = ax)\n", "# set significance bar\n", "ax.axhline(y = 1.96,linestyle = '--',color = pal[9])\n", "ax.set_xticks(x)\n", "ax.set_xticklabels(networkLabs,rotation=90)\n", "ax.set_ylabel(\"Predictor Importance (Z-Score)\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[204]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["plot nulls themselves"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig,ax = plt.subplots(1,1)\n", "sns.barplot(data = centnulldf,x = \"Network\",y = \"Null\",palette = \"Paired\",ax = ax)\n", "ax.set_xticks(x)\n", "ax.set_xticklabels(networkLabs,rotation=90)\n", "ax.set_ylabel(\"Average Centroid Difference\")\n", "plt.show()\n", "# feature correlation"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### plot results to distinguish differences between correct and incorrect patients"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[205]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["first reorganized the results dataframe"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dfX = pd.DataFrame(X, columns = networkLabs)\n", "dfX[\"Subject\"] = np.arange(0,nSub).astype(\"int\")\n", "dfX = dfX.melt(id_vars = \"Subject\", value_vars = networkLabs)\n", "dfM = pd.merge(left = dfOutcome.reset_index(), right = dfX,left_on = \"level_0\", right_on = \"Subject\")\n", "dfM.rename(columns = {\"variable\" : \"network\"},inplace = True)\n", "dfM[\"ResultTrue\"] = dfM[\"ResultTrue\"].apply(lambda x: \"Correctly Labeled\" if x else \"Incorrectly Labeled\")\n", "dfM[\"ID-TF\"] =  dfM[\"ResultTrue\"]\n", "dfM.loc[dfM[\"ResultTrue\"] == \"Incorrectly Labeled\",\"ID-TF\"] = \\\n", "    dfM.loc[dfM[\"ResultTrue\"] == \"Incorrectly Labeled\",\"StudyID\"]\n", "dfM[\"ID-TF\"] = dfM[\"ID-TF\"].apply(lambda x: str(\"Patient \" + str(round(x))) if type(x) == float else x)\n", "sns.catplot(data = dfM, x = \"network\", y = \"value\", row = Var, hue = \"ResultTrue\", kind = \"point\")\n", "plt.xticks(rotation = 65)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[209]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["also look at the incorrect predicted subjects more directly<br>\n", "set plotting themes"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.set_theme(style = \"white\", rc={'figure.figsize': (4.5,3.1),\"xtick.labelsize\": 10,             'xtick.alignment':'center',\"ytick.labelsize\": 10,'font.family':'Arial','figure.dpi':600,\"legend.fontsize\":10,             \"axes.labelsize\":12,\"figure.facecolor\":\"w\",\"axes.spines.right\": False,\"axes.spines.left\": False,                \"axes.spines.top\": False,\"axes.spines.bottom\": False})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[212]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots(nrows = 2,sharex = True,sharey = True)\n", "sns.pointplot(data = dfM[dfM[Var] == 0], x = \"network\", y = \"value\", hue = \"ID-TF\", row = Var,ax = ax[0],              palette = [pal[0],pal[1],pal[2],pal[3]])\n", "sns.pointplot(data = dfM[dfM[Var]], x = \"network\", y = \"value\", hue = \"ID-TF\", row = Var,ax = ax[1],              palette = [pal[-5],pal[-3],pal[-4]])\n", "#fig.supylabel(\"Spatial Correlation\")\n", "#fig.supxlabel(\"Network\")\n", "ax[0].legend([],frameon=False); ax[1].legend([],frameon=False); \n", "ax[0].legend(bbox_to_anchor=(1.05, 1)); ax[1].legend(bbox_to_anchor=(1.05, 1));\n", "ax[0].set_xlabel(''); ax[1].set_xlabel('')\n", "ax[0].set_ylabel(''); ax[1].set_ylabel('')\n", "plt.xticks(rotation = 90)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["look at cross correlation between networks<br>\n", "set plotting themes"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.set_theme(style = \"white\", rc={'figure.figsize': (3.14,3.1),\"xtick.labelsize\": 10,             'xtick.alignment':'center',\"ytick.labelsize\": 10,'font.family':'Arial','figure.dpi':600,\"legend.fontsize\":10,             \"axes.labelsize\":12,\"figure.facecolor\":\"w\",\"axes.spines.right\": False,\"axes.spines.left\": False,                \"axes.spines.top\": False,\"axes.spines.bottom\": False})\n", "fig, ax = plt.subplots()\n", "sns.heatmap(np.corrcoef(Xo.T),cmap = sns.color_palette(\"vlag\", as_cmap=True),vmin = -1, vmax = 1)\n", "plt.xticks(np.arange(0,len(networkLabs)),networkLabs,rotation = 90)\n", "plt.yticks(np.arange(0.5,len(networkLabs) + 0.5),networkLabs,rotation = 0)\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}